<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="数据文件夹中均是食物的照片，共有11类，Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles&#x2F;Pasta, Rice, Seafood, Soup, and Vegetable&#x2F;Fruit.我们要创建一个CNN，用来实现食物的分类。数据集有训练集、验证集、测试集。训练集和验证集带标签，测试集不带标签。 库导入首先导入各种库，并设">
<meta property="og:type" content="article">
<meta property="og:title" content="图片分类">
<meta property="og:url" content="http://example.com/2023/08/07/food/index.html">
<meta property="og:site_name" content="暑期实习博客">
<meta property="og:description" content="数据文件夹中均是食物的照片，共有11类，Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles&#x2F;Pasta, Rice, Seafood, Soup, and Vegetable&#x2F;Fruit.我们要创建一个CNN，用来实现食物的分类。数据集有训练集、验证集、测试集。训练集和验证集带标签，测试集不带标签。 库导入首先导入各种库，并设">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-07T11:20:45.771Z">
<meta property="article:modified_time" content="2023-08-10T04:56:41.239Z">
<meta property="article:author" content="时骅">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2023/08/07/food/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>图片分类 | 暑期实习博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">暑期实习博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/08/07/food/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="时骅">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="暑期实习博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          图片分类
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-08-07 19:20:45" itemprop="dateCreated datePublished" datetime="2023-08-07T19:20:45+08:00">2023-08-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-08-10 12:56:41" itemprop="dateModified" datetime="2023-08-10T12:56:41+08:00">2023-08-10</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>数据文件夹中均是食物的照片，共有11类，Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles/Pasta, Rice, Seafood, Soup, and Vegetable/Fruit.我们要创建一个CNN，用来实现食物的分类。<br>数据集有训练集、验证集、测试集。训练集和验证集带标签，测试集不带标签。</p>
<h3 id="库导入"><a href="#库导入" class="headerlink" title="库导入"></a>库导入</h3><p>首先导入各种库，并设置了一个随机种子，这将确保实验结果可以重现。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">_exp_name = <span class="string">&quot;sample&quot;</span></span><br><span class="line"><span class="comment"># Import necessary packages.</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="comment"># &quot;ConcatDataset&quot; and &quot;Subset&quot; are possibly useful when doing semi-supervised learning.</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> ConcatDataset, DataLoader, Subset, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> DatasetFolder, VisionDataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is for the progress bar.</span></span><br><span class="line"><span class="keyword">from</span> tqdm.auto <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">myseed = <span class="number">6666</span>  <span class="comment"># set a random seed for reproducibility</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line"><span class="comment">#torch.backends.cudnn.enable = True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">np.random.seed(myseed)</span><br><span class="line">random.seed(myseed)</span><br><span class="line">torch.manual_seed(myseed)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    torch.cuda.manual_seed_all(myseed)</span><br></pre></td></tr></table></figure></p>
<h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>在测试和验证阶段通常不需要数据增强，只需要将PIL图像调整大小并转换为张量。可以使用transforms.Resize将图像大小调整为128x128，<br>并使用transforms.ToTensor将其转换为张量。这样可以确保测试和验证阶段的一致性，使结果可比较。<br>然而，如果希望在测试阶段使用数据增强，您可以使用train_tfm来产生图像，然后使用集成方法进行测试。train_tfm包含了一系列的数据增强操作，如随机裁剪、水平翻转、垂直翻转、随机旋转、随机仿射变换和随机灰度转换。这些增强操作可以增加模型的鲁棒性，提高模型在测试集上的性能。<br>数据增强在训练阶段通常是必需的，因为它可以增加训练数据的多样性，提高模型的泛化能力。但在测试和验证阶段，我们通常希望评估模型在真实数据上的性能，因此不需要进行数据增强。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Normally, We don&#x27;t need augmentations in testing and validation.</span></span><br><span class="line"><span class="comment"># All we need here is to resize the PIL image and transform it into Tensor.</span></span><br><span class="line">test_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    <span class="comment">#transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># However, it is also possible to use augmentation in the testing phase.</span></span><br><span class="line"><span class="comment"># You may use train_tfm to produce a variety of images and then test using ensemble methods</span></span><br><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop((<span class="number">128</span>, <span class="number">128</span>), scale=(<span class="number">0.7</span>, <span class="number">1.0</span>)),</span><br><span class="line">    transforms.RandomHorizontalFlip(<span class="number">0.5</span>),</span><br><span class="line">    transforms.RandomVerticalFlip(<span class="number">0.5</span>),</span><br><span class="line">    transforms.RandomRotation(<span class="number">180</span>),</span><br><span class="line">    transforms.RandomAffine(<span class="number">30</span>),</span><br><span class="line">    transforms.RandomGrayscale(p=<span class="number">0.2</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure></p>
<h3 id="数据集定义"><a href="#数据集定义" class="headerlink" title="数据集定义"></a>数据集定义</h3><p>创建数据集类FoodDataset，用于加载图像数据集并进行相应的数据预处理。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FoodDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,path=<span class="literal">None</span>,tfm=test_tfm,files=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(FoodDataset).__init__()</span><br><span class="line">        self.path = path</span><br><span class="line">        <span class="keyword">if</span> path:</span><br><span class="line">            self.files = <span class="built_in">sorted</span>([os.path.join(path, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(path) <span class="keyword">if</span> x.endswith(<span class="string">&quot;.jpg&quot;</span>)])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.files = files</span><br><span class="line">        self.transform = tfm</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Num of element: &#x27;</span>, <span class="built_in">len</span>(self.files))</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.files)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        fname = self.files[idx]</span><br><span class="line">        im = Image.<span class="built_in">open</span>(fname)</span><br><span class="line">        im = self.transform(im)</span><br><span class="line">        <span class="comment">#im = self.data[idx]</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            label = <span class="built_in">int</span>(fname.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>].split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            label = -<span class="number">1</span> <span class="comment"># test has no label</span></span><br><span class="line">        <span class="keyword">return</span> im,label</span><br></pre></td></tr></table></figure><br>接下来是对残差块（Residual Block）的定义，它是深度残差网络（ResNet）的基本组成单元。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Residual_Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ic, oc, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(ic, oc, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(oc),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(oc, oc, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(oc),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">        self.downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> (ic != oc):</span><br><span class="line">            self.downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(ic, oc, kernel_size=<span class="number">1</span>, stride=stride),</span><br><span class="line">                nn.BatchNorm2d(oc),</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.downsample:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">            </span><br><span class="line">        out += residual</span><br><span class="line">        <span class="keyword">return</span> self.relu(out)</span><br></pre></td></tr></table></figure><br>接下来是对分类器模型的定义，它基于残差块构建了一个深度卷积神经网络。<br>首先，定义了一个预处理卷积层preconv，它包含一个7x7的卷积操作、批归一化和ReLU激活函数。<br>接下来，通过调用make_residual方法构建了四个残差层，分别是layer0、layer1、layer2和layer3。每个残差层都使用make_residual方法生成。<br>最后，定义了一个全连接层fc，它包含了一系列的操作，包括Dropout、线性变换、批归一化和ReLU激活函数。最后一层线性变换的输出维度为num_classes，表示最终的分类结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Classifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, num_layers, num_classes=<span class="number">11</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.preconv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.layer0 = self.make_residual(block, <span class="number">32</span>, <span class="number">64</span>,  num_layers[<span class="number">0</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer1 = self.make_residual(block, <span class="number">64</span>, <span class="number">128</span>, num_layers[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer2 = self.make_residual(block, <span class="number">128</span>, <span class="number">256</span>, num_layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self.make_residual(block, <span class="number">256</span>, <span class="number">512</span>, num_layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#self.avgpool = nn.AvgPool2d(2)</span></span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Sequential(            </span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_residual</span>(<span class="params">self, block, ic, oc, num_layer, stride=<span class="number">1</span></span>):</span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(ic, oc, stride))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_layer):</span><br><span class="line">            layers.append(block(oc, oc))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># [3, 128, 128]</span></span><br><span class="line">        out = self.preconv(x)  <span class="comment"># [32, 64, 64]</span></span><br><span class="line">        out = self.layer0(out) <span class="comment"># [64, 32, 32]</span></span><br><span class="line">        out = self.layer1(out) <span class="comment"># [128, 16, 16]</span></span><br><span class="line">        out = self.layer2(out) <span class="comment"># [256, 8, 8]</span></span><br><span class="line">        out = self.layer3(out) <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        <span class="comment">#out = self.avgpool(out) # [512, 2, 2]</span></span><br><span class="line">        out = self.fc(out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)) </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><br>最后定义两个损失函数。<br>FocalLoss是一种改进的交叉熵损失函数，用于解决类别不平衡问题。<br>MyCrossEntropy是一个简单的交叉熵损失函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, class_num, alpha=<span class="literal">None</span>, gamma=<span class="number">2</span>, size_average=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> alpha <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.alpha = Variable(torch.ones(class_num, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(alpha, Variable):</span><br><span class="line">                self.alpha = alpha</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.alpha = Variable(alpha)</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.class_num = class_num</span><br><span class="line">        self.size_average = size_average</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, targets</span>):</span><br><span class="line">        N = inputs.size(<span class="number">0</span>)</span><br><span class="line">        C = inputs.size(<span class="number">1</span>)</span><br><span class="line">        P = F.softmax(inputs, dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        class_mask = inputs.data.new(N, C).fill_(<span class="number">0</span>)</span><br><span class="line">        class_mask = Variable(class_mask)</span><br><span class="line">        ids = targets.view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        class_mask.scatter_(<span class="number">1</span>, ids.data, <span class="number">1.</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> inputs.is_cuda <span class="keyword">and</span> <span class="keyword">not</span> self.alpha.is_cuda:</span><br><span class="line">            self.alpha = self.alpha.cuda()</span><br><span class="line">        alpha = self.alpha[ids.data.view(-<span class="number">1</span>)]</span><br><span class="line">        probs = (P*class_mask).<span class="built_in">sum</span>(<span class="number">1</span>).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        log_p = probs.log()</span><br><span class="line">        </span><br><span class="line">        batch_loss = -alpha*(torch.<span class="built_in">pow</span>((<span class="number">1</span>-probs), self.gamma))*log_p</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.size_average:</span><br><span class="line">            loss = batch_loss.mean()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss = batch_loss.<span class="built_in">sum</span>()</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyCrossEntropy</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, class_num</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><br>定义一些参数，并准备数据集。将训练集目录与验证集目录进行路径拼接得到完整的文件路径列表。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">num_layers = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>] <span class="comment"># residual number layers</span></span><br><span class="line">alpha = torch.Tensor([<span class="number">1</span>, <span class="number">2.3</span>, <span class="number">0.66</span>, <span class="number">1</span>, <span class="number">1.1</span>, <span class="number">0.75</span>, <span class="number">2.3</span>, <span class="number">3.5</span>, <span class="number">1.1</span>, <span class="number">0.66</span>, <span class="number">1.4</span>])</span><br><span class="line">n_epochs = <span class="number">300</span></span><br><span class="line">patience = <span class="number">16</span> <span class="comment"># If no improvement in &#x27;patience&#x27; epochs, early stop</span></span><br><span class="line">k_fold = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">train_dir = <span class="string">&quot;food11/training&quot;</span></span><br><span class="line">val_dir = <span class="string">&quot;food11/validation&quot;</span></span><br><span class="line"></span><br><span class="line">train_files = [os.path.join(train_dir, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(train_dir) <span class="keyword">if</span> x.endswith(<span class="string">&#x27;.jpg&#x27;</span>)]</span><br><span class="line">val_files = [os.path.join(val_dir, x) <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(val_dir) <span class="keyword">if</span> x.endswith(<span class="string">&#x27;.jpg&#x27;</span>)]</span><br><span class="line">total_files = train_files + val_files</span><br><span class="line">random.shuffle(total_files)</span><br><span class="line"></span><br><span class="line">num = <span class="built_in">len</span>(total_files) // k_fold</span><br></pre></td></tr></table></figure></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>下面是一个训练和验证的循环，其中包含了模型的初始化、数据集的准备、训练和验证的过程。<br>首先，代码判断是否有可用的GPU，如果有，则将设备设置为”cuda”，否则设置为”cpu”。然后打印出当前设备。<br>接下来，代码使用一个循环来进行交叉验证。对于每个折叠（fold），代码会初始化一个模型，并将其移动到指定的设备上。同时，还会初始化损失函数（使用Focal Loss）和优化器（使用Adam优化器），以及一些用于记录训练过程的变量。<br>在每个训练周期（epoch）中，代码会将模型设置为训练模式，并遍历训练数据集。对于每个批次（batch），代码会前向传播数据，计算损失和准确率，并进行反向传播和参数更新。同时，还会记录训练过程中的损失和准确率。<br>在每个验证周期（epoch）中，代码会将模型设置为评估模式，并遍历验证数据集。对于每个批次，代码会前向传播数据，计算损失和准确率，并记录下来。<br>在每个验证周期结束后，代码会计算整个验证集的平均损失和准确率，并与之前的最佳准确率进行比较。如果当前准确率更好，则保存模型，并更新最佳准确率。如果连续若干个验证周期都没有提升，则提前停止训练。<br>整个训练和验证过程会在每个折叠上进行，最终得到的模型是在所有折叠上训练得到的最佳模型。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &quot;cuda&quot; only when GPUs are available.</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="built_in">print</span>(device)</span><br><span class="line"></span><br><span class="line">test_fold = k_fold</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(test_fold):</span><br><span class="line">    fold = i+<span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;\n\nStarting Fold: <span class="subst">&#123;fold&#125;</span> ********************************************&#x27;</span>)</span><br><span class="line">    model = Classifier(Residual_Block, num_layers).to(device)</span><br><span class="line">    criterion = FocalLoss(<span class="number">11</span>, alpha=alpha)</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.0004</span>, weight_decay=<span class="number">1e-5</span>) </span><br><span class="line">    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=<span class="number">16</span>, T_mult=<span class="number">1</span>)</span><br><span class="line">    stale = <span class="number">0</span></span><br><span class="line">    best_acc = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    val_data = total_files[i*num: (i+<span class="number">1</span>)*num]</span><br><span class="line">    train_data = total_files[:i*num] + total_files[(i+<span class="number">1</span>)*num:]</span><br><span class="line">    </span><br><span class="line">    train_set = FoodDataset(tfm=train_tfm, files=train_data)</span><br><span class="line">    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    valid_set = FoodDataset(tfm=test_tfm, files=val_data)</span><br><span class="line">    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># ---------- Training ----------</span></span><br><span class="line">        <span class="comment"># Make sure the model is in train mode before training.</span></span><br><span class="line">        model.train()</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># These are used to record information in training.</span></span><br><span class="line">        train_loss = []</span><br><span class="line">        train_accs = []</span><br><span class="line">        lr = optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]</span><br><span class="line">        </span><br><span class="line">        pbar = tqdm(train_loader)</span><br><span class="line">        pbar.set_description(<span class="string">f&#x27;T: <span class="subst">&#123;epoch+<span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> pbar:</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># A batch consists of image data and corresponding labels.</span></span><br><span class="line">            imgs, labels = batch</span><br><span class="line">            <span class="comment"># Calculate the cross-entropy loss.</span></span><br><span class="line">            <span class="comment"># We don&#x27;t need to apply softmax before computing cross-entropy as it is done automatically.</span></span><br><span class="line">            loss = criterion(logits, labels.to(device))</span><br><span class="line">            <span class="comment"># Gradients stored in the parameters in the previous step should be cleared out first.</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            <span class="comment"># Compute the gradients for parameters.</span></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># Clip the gradient norms for stable training.</span></span><br><span class="line">            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">10</span>)</span><br><span class="line">            <span class="comment"># Update the parameters with computed gradients.</span></span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="comment"># Compute the accuracy for current batch.</span></span><br><span class="line">            acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device)).<span class="built_in">float</span>().mean()</span><br><span class="line">            <span class="comment"># Record the loss and accuracy.</span></span><br><span class="line">            train_loss.append(loss.item())</span><br><span class="line">            train_accs.append(acc)</span><br><span class="line">            pbar.set_postfix(&#123;<span class="string">&#x27;lr&#x27;</span>:lr, <span class="string">&#x27;b_loss&#x27;</span>:loss.item(), <span class="string">&#x27;b_acc&#x27;</span>:acc.item(),</span><br><span class="line">                    <span class="string">&#x27;loss&#x27;</span>:<span class="built_in">sum</span>(train_loss)/<span class="built_in">len</span>(train_loss), <span class="string">&#x27;acc&#x27;</span>: <span class="built_in">sum</span>(train_accs).item()/<span class="built_in">len</span>(train_accs)&#125;)</span><br><span class="line">        </span><br><span class="line">        scheduler.step()</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># These are used to record information in validation.</span></span><br><span class="line">        valid_loss = []</span><br><span class="line">        valid_accs = []</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Iterate the validation set by batches.</span></span><br><span class="line">        pbar = tqdm(valid_loader)</span><br><span class="line">        pbar.set_description(<span class="string">f&#x27;V: <span class="subst">&#123;epoch+<span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> pbar:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># A batch consists of image data and corresponding labels.</span></span><br><span class="line">            imgs, labels = batch</span><br><span class="line">  </span><br><span class="line">            <span class="comment"># We don&#x27;t need gradient in validation.</span></span><br><span class="line">            <span class="comment"># Using torch.no_grad() accelerates the forward process.</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                logits = model(imgs.to(device))</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># We can still compute the loss (but not the gradient).</span></span><br><span class="line">            loss = criterion(logits, labels.to(device))</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># Compute the accuracy for current batch.</span></span><br><span class="line">            acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device)).<span class="built_in">float</span>().mean()</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># Record the loss and accuracy.</span></span><br><span class="line">            valid_loss.append(loss.item())</span><br><span class="line">            valid_accs.append(acc)</span><br><span class="line">            pbar.set_postfix(&#123;<span class="string">&#x27;v_loss&#x27;</span>:<span class="built_in">sum</span>(valid_loss)/<span class="built_in">len</span>(valid_loss), </span><br><span class="line">                              <span class="string">&#x27;v_acc&#x27;</span>: <span class="built_in">sum</span>(valid_accs).item()/<span class="built_in">len</span>(valid_accs)&#125;)</span><br><span class="line">        </span><br><span class="line">            <span class="comment">#break</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment"># The average loss and accuracy for entire validation set is the average of the recorded values.</span></span><br><span class="line">        valid_loss = <span class="built_in">sum</span>(valid_loss) / <span class="built_in">len</span>(valid_loss)</span><br><span class="line">        valid_acc = <span class="built_in">sum</span>(valid_accs) / <span class="built_in">len</span>(valid_accs)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">        <span class="keyword">if</span> valid_acc &gt; best_acc:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Best model found at fold <span class="subst">&#123;fold&#125;</span> epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, acc=<span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span>, saving model&quot;</span>)</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">f&quot;Fold_<span class="subst">&#123;fold&#125;</span>_best.ckpt&quot;</span>)</span><br><span class="line">            <span class="comment"># only save best to prevent output memory exceed error</span></span><br><span class="line">            best_acc = valid_acc</span><br><span class="line">            stale = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            stale += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> stale &gt; patience:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;No improvment <span class="subst">&#123;patience&#125;</span> consecutive epochs, early stopping&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<h3 id="测试并生成预测表"><a href="#测试并生成预测表" class="headerlink" title="测试并生成预测表"></a>测试并生成预测表</h3><p>最后对测试数据进行预测。<br>首先，代码创建了一个空列表models，用于存储每个折叠上的最佳模型。<br>然后，代码使用一个循环，对每个折叠进行操作。在每个折叠中，代码会初始化一个模型model_best，并加载之前保存的最佳模型的参数。然后，将模型设置为评估模式。最后，将模型添加到models列表中。<br>接下来，代码使用torch.no_grad()禁用梯度计算。然后，对于测试数据集中的每个批次，代码会使用每个折叠上的模型进行预测。预测结果会进行累加，并通过np.argmax函数找到每个样本的最大预测值对应的类别。最后，将预测结果添加到prediction列表中。<br>最终，prediction列表中存储了所有测试样本的预测结果。<br>最后创建测试集的CSV文件，以便提交预测结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">models = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(test_fold):</span><br><span class="line">    fold = i + <span class="number">1</span></span><br><span class="line">    model_best = Classifier(Residual_Block, num_layers).to(device)</span><br><span class="line">    model_best.load_state_dict(torch.load(<span class="string">f&quot;Fold_<span class="subst">&#123;fold&#125;</span>_best.ckpt&quot;</span>))</span><br><span class="line">    model_best.<span class="built_in">eval</span>()</span><br><span class="line">    models.append(model_best)</span><br><span class="line"></span><br><span class="line">prediction = []            </span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data,_ <span class="keyword">in</span> test_loader:</span><br><span class="line">        test_preds = [] </span><br><span class="line">        <span class="keyword">for</span> model_best <span class="keyword">in</span> models:</span><br><span class="line">            test_preds.append(model_best(data.to(device)).cpu().data.numpy())</span><br><span class="line">        test_preds = <span class="built_in">sum</span>(test_preds)</span><br><span class="line">        test_label = np.argmax(test_preds, axis=<span class="number">1</span>)</span><br><span class="line">        prediction += test_label.squeeze().tolist()</span><br><span class="line"></span><br><span class="line"><span class="comment">#create test csv</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pad4</span>(<span class="params">i</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;0&quot;</span>*(<span class="number">4</span>-<span class="built_in">len</span>(<span class="built_in">str</span>(i)))+<span class="built_in">str</span>(i)</span><br><span class="line">df = pd.DataFrame()</span><br><span class="line">df[<span class="string">&quot;Id&quot;</span>] = [pad4(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(test_set)+<span class="number">1</span>)]</span><br><span class="line">df[<span class="string">&quot;Category&quot;</span>] = prediction</span><br><span class="line">df.to_csv(<span class="string">&quot;submission.csv&quot;</span>,index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/08/04/frame/" rel="prev" title="音位分类">
      <i class="fa fa-chevron-left"></i> 音位分类
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/08/12/GLUE/" rel="next" title="基于transformers的京东零售NLP任务">
      基于transformers的京东零售NLP任务 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%93%E5%AF%BC%E5%85%A5"><span class="nav-number">1.</span> <span class="nav-text">库导入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="nav-number">2.</span> <span class="nav-text">数据增强</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9A%E4%B9%89"><span class="nav-number">3.</span> <span class="nav-text">数据集定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-number">4.</span> <span class="nav-text">训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E5%B9%B6%E7%94%9F%E6%88%90%E9%A2%84%E6%B5%8B%E8%A1%A8"><span class="nav-number">5.</span> <span class="nav-text">测试并生成预测表</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">时骅</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">时骅</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

  

</body>
</html>
